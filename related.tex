\section{Related Work}

The problem of memory pressure in a system has been studied for several years. Different methods have been proposed to address this issue, such as tuning of garbage collection, memory management and task scheduling. Most of these works focus on the offline calculation in data processing systems. 

\textbf{Garbage Collection} Most methods of garbage collection tuning are based on the features of different applications, such as Spark applications~\cite{www:spark-tuning}, Cassandra applications~\cite{www:cassandra}. These methods typically take the following two approaches: 1) replacing other garbage collection algorithms, such as Concurrent Mark Sweep (CMS) or Garbage First (G1), 2) tuning the important parameters, such as the ratio of young generation and old generation, to avoid frequent GC activity and data copying. Most researches attempt to rebuild the algorithm of garbage collection for common applications. For example, Yang et al.\cite{yang:fullgc} describes an incremental query model for reference calculations to optimize the cause of full GC. This garbage collection algorithm is universally useful to most memory pressure cases. Rodrigo et al.\cite{rodigo:NGeneration} proposed a N-Generational garbage collector for big data memory management, which also reduces the data copying in garbage collection. Tuning garbage collection requires the deep understanding and proficient skills on the data processing systems.

\textbf{Memory Management} The memory analysis of data-intensive big data applications are put forward by Bu et al.~\cite{bu:bloat}. They consider the bloat of memory in object-oriented languages and design the bloat-aware paradigm: 1) merging small data to big data; 2) manipulating the data by directly accessing the buffers. Some memory management techniques at the system level also extend the language-level optimization, such as region based memory management (RBMM)~\cite{nguyen2015facade, nguyen:yak} and lifetime based memory management~\cite{lulu:deca}. Nguyen et al.~\cite{nguyen2015facade} advise the users to mark the class information in the applications to decompose the data object to regions. Then the memory can be allocated or reclaimed by the regions. Based on the same theory, they also proposed a new garbage collector to mange the data objects and control the objects separately to extend the method to iterative computations~\cite{nguyen:yak}. Lu et al.~\cite{lulu:deca} propose the lifetime-based memory management. They decompose the data objects based on the data container, which decides the lifetime of data objects. The decomposed data objects will impose less pressure on the memory and can be allocated and reclaimed by regions. Memory management provides an effective way to manage the memory pressure and has been investigated by a large body of research.

\textbf{Task Scheduler} As the memory pressure is caused by the running tasks, the task scheduler can also play a role in releasing the memory pressure or improving the efficiency of memory usage. Fang et al.~\cite{fang2015interruptible} design the interruptible tasks for data-parallel programs. They classify the memory consumption of a task into four parts: local data structures, processed input, unprocessed input and result. Based on their novel programming model, suspending the interruptible tasks can release parts of the memory consumption of random tasks when memory pressure mounts. The suspended tasks can be resumed when memory pressure decreases. 
%Interruptible tasks can be resumed with the remaining in-memory data. 
Pu et al.~\cite{pu2016fairride} implement a new policy called FairRide, which  is able to fairly allocate the memory cache to multiple users with the shared files through the efficient blocking. This policy is the first to satisfy all three desirable properties: isolation-guarantee, strategy-proofness and Pareto-efficiency. Based on different scheduling standards, the task scheduler always adapts to different demands and is easy to be implemented.
